{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course reminder\n",
    "\n",
    "Matrix factorisation consists in expressing one matrix as the product of two smaller matrices. The idea is to have a lower rank approximation of the original matrix. This lower rank approximation relies on an approximation of the latent factors and thus offers an insight on the problem.\n",
    "\n",
    "Applications include signal decomposition, where a matrix of signals is decomposed into a set of base components along with a mixing matrix. In recommender systems, considering a matrix of user ratings for movies, matrix factorisation infers the latent characteristics of the movies and the affinity of users for each of them.\n",
    "\n",
    "Given a matrix $\\mathbf{R} \\in \\mathbb{R}^{n \\times m}$, we want to find the matrices $\\mathbf{P} \\in \\mathbb{R}^{n \\times k}$ and $\\mathbf{Q} \\in \\mathbb{R}^{m \\times k}$ such as\n",
    "$$\\hat{\\mathbf{R}} = \\mathbf{P} \\cdot \\mathbf{Q}^\\top \\approx \\mathbf{R}$$\n",
    "\n",
    "\n",
    "# Exercice 1 - The gradient descent\n",
    "\n",
    "The simplest way to compute the matrices $\\mathbf{P}$ and $\\mathbf{Q}$ is to use a gradient descent. It consists in initializing the estimated matrices randomly, compute their difference to the real data, and follow the gradient of the values to reach a minimum.\n",
    "\n",
    "I this exercise, we will consider a divergence based on the Euclidean distance: the Frobenius norm:\n",
    "\n",
    "$$\\min_{\\mathbf{P}, \\mathbf{Q} > 0} \\| \\mathbf{R} - \\mathbf{P} \\cdot \\mathbf{Q}^\\top\\|^2_F$$\n",
    "\n",
    "\n",
    "## The Squared Error\n",
    "\n",
    "The goal here is to minimize the reconstruction error. The first step is to compute this error. Write below a function that computes the formula for this error given $\\mathbf{R}$, $\\mathbf{P}$, $\\mathbf{Q}$ and two indices $i$ and $j$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(R, P, Qt):\n",
    "    return np.linalg.norm(R - P @ Qt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving the update function for $\\mathbf{P}$\n",
    "\n",
    "Now that we have the error, we need to minimize it with regard to $\\mathbf{P}$. First, derive the formula above, with regard to $\\mathbf{P}$. Then, write, the update function for $\\mathbf{P}$. We call $\\alpha$ the parameter related to the gradient descent update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∥XW - Y∥\n",
    "# 2(XW - Y) W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nW=random(n, r)\\nfor i= 1à Maxiter\\ndo\\n    Résoudre en H: W′WH = W′X\\n    Mettre à 0 les termes négatifs de H\\n    Résoudre en W:HH′W′= HX′\\n    Mettre à 0 les termes négatifs de W\\nend for\\n'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "W=random(n, r)\n",
    "for i= 1à Maxiter\n",
    "do\n",
    "    Résoudre en H: W′WH = W′X\n",
    "    Mettre à 0 les termes négatifs de H\n",
    "    Résoudre en W:HH′W′= HX′\n",
    "    Mettre à 0 les termes négatifs de W\n",
    "end for\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_P(R, P, Qt, alpha):\n",
    "    P += alpha *  2 * (R - P @ Qt) @ Qt.T # Differentielle\n",
    "    return P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving the update function for $\\mathbf{Q}$\n",
    "\n",
    "Do the same for $\\mathbf{Q}$. Both matrices being symmetrical in the formulation of the problem, it boils down to replacing swapping $\\mathbf{P}$ by $\\mathbf{Q}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q(R, P, Qt, alpha):\n",
    "    Q = Qt.T\n",
    "    Q += alpha * 2 * (R - P @ Qt).T @ P\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating\n",
    "\n",
    "Now that the update functions are coded, all that remains is to iterate and stop at a given criterion. The best is to go for the common methods: having a limited number of steps and a tolerance depending on the value of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, es=None):\n",
    "    # do something\n",
    "    for k in range(steps):\n",
    "        Q = update_Q(R, P, Q.T, alpha)\n",
    "        np.clip(Q, a_min=0, a_max=None)\n",
    "        P = update_P(R, P, Q.T, alpha)\n",
    "        np.clip(P, a_min=0, a_max=None)\n",
    "        if es is not None:\n",
    "            es.append(error(R,P,Q.T))\n",
    "        \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example\n",
    "\n",
    "For sanity check, let us tun this algorithm on a toy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 3 0 1]\n",
      " [4 0 0 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n",
      "[[ 5.18109624  1.93968992 -0.66134121  1.49809219]\n",
      " [ 3.4465793   1.29816685 -0.40644451  1.05658066]\n",
      " [ 1.48487939  1.0233782   1.80699125  4.00683425]\n",
      " [ 1.1194502   0.78476562  1.41884157  3.12208305]\n",
      " [-0.39158452  0.54229546  2.99219688  5.15879069]]\n",
      "Miam!\n"
     ]
    }
   ],
   "source": [
    "R = [\n",
    "     [5,3,0,1],\n",
    "     [4,0,0,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    " \n",
    "R = np.array(R)\n",
    " \n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    "\n",
    "es = []\n",
    "nP, nQ = matrix_factorization(R, P, Q, K, steps=100000, alpha=0.0001, es=es)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "\n",
    "\n",
    "print(R)\n",
    "print(nR)\n",
    "#print(P@Q.T)\n",
    "print(\"Miam!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging\n",
    "Debugging machine learning algorithms is most of the time tedious. For this algorithm, we have one guarantee: The global loss should decrease at each iteration. One good reflex is to log this information (if you code a ML API for somebody else, providing that kind of feature will be greatly appreciated). There are two common ways to provide this information. The first one is to add a verbose mode and print the loss. A graph can then be crafted using grep. The second option, in particular for Python, is to provide a list as an option. If the list is present, it will be fed with the value of the loss at each iteration. Implement the latter and display below the plot of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcf46c6c7b8>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison with an existing implementation\n",
    "Scikit-learn is a very famous ML package for Python. They do provide an implementation of the NMF algorithm. Compare your implementation to theirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.2558264  1.99313836 0.         1.45512772]\n",
      " [3.50429478 1.32891458 0.         0.9701988 ]\n",
      " [1.31294288 0.94415991 1.94956896 3.94609389]\n",
      " [0.98129195 0.72179987 1.52759811 3.0788454 ]\n",
      " [0.         0.65008935 2.84003662 5.21894555]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "nmf = NMF(n_components=2)\n",
    "W = nmf.fit_transform(R)\n",
    "H = nmf.components_\n",
    "print(np.dot(W, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding regularization\n",
    "If you run the script several times, you may notice that the reconstruction is good but the matrices $\\mathbf{P}$ and $\\mathbf{Q}$ change a lot. A way to fix this problem is to inject more information in the model. It is most of the time done under the the form of a regularization.\n",
    "\n",
    "The regularization is a term added to the loss that add a constraint on the resulting matrices. The constraint must be adapted to the needs. In the following, we use NMF for the purpose of topic extraction.\n",
    "\n",
    "In the following, we want to add an L1 and L2 regularizers to the previous algorithm.\n",
    "\n",
    "A famous application, in particular for L1 norm is the processing of text information. In the following example, we want to extract the topics out of a corpus of documents. The first step is compute the tf-idf measure for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]\n",
    "\n",
    "# Get all unique words\n",
    "words = [words for doc in documents for words in doc]\n",
    "words = np.unique(words)\n",
    "\n",
    "# Create a matrix for tfidf values\n",
    "tfidf = np.zeros((len(documents), len(words)))\n",
    "\n",
    "# For each term, compute its idf\n",
    "idfs = []\n",
    "for word in words:\n",
    "    count = np.sum([word in doc for doc in documents])\n",
    "    idfs.append(np.log(len(documents) / count))\n",
    "    \n",
    "# Now fill the tfidf matrix\n",
    "for iw, word, idf in zip(range(len(words)), words, idfs):\n",
    "    for id, doc in enumerate(documents):\n",
    "        tfidf[id, iw] = np.sum(np.asarray(doc) == word) / len(doc) * idf\n",
    "        \n",
    "R = tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a matrix of data, we can use it with our previous algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 4\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\mathbf{Q}$ matrix contains, for each word, a score indicating its affinity with each topic. A first sanity check for this algorithm is to look at the 5 top words for each topic.\n",
    "\n",
    "Print them under the following pattern:\n",
    "\n",
    "Topic 1: Hadoop, C++, Python, R, NoSQL\n",
    "\n",
    "Topic 2: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "['Mahout' 'neural networks' 'Cassandra' 'probability' 'MongoDB'\n",
      " 'support vector machines' 'regression']\n",
      "Topic 2\n",
      "['MapReduce' 'Big Data' 'Storm' 'Mahout' 'Spark' 'NoSQL' 'Postgres']\n",
      "Topic 3\n",
      "['statsmodels' 'NoSQL' 'statistics' 'Postgres' 'C++' 'Cassandra'\n",
      " 'databases']\n",
      "Topic 4\n",
      "['libsvm' 'numpy' 'pandas' 'scipy' 'deep learning'\n",
      " 'support vector machines' 'Big Data']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting graph to look at is the matrix of weights in Q. We expect each line of $\\mathbf{Q}^\\top$ (or topic) to contain strongly differentiated values to indicate that the topics are well segmented. Is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8a9bb00>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABICAYAAAANm7UyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqbmLiJSQmruISAmpuYuIlND/AECE1+gionZqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a50470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(nQ.T, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding an L2 penalization\n",
    "Usually, the l2 penalization is applied on both matrices $\\mathbf{P}$ and $\\mathbf{Q}$. The elements that must be updated are:\n",
    "* the loss\n",
    "* the update of $\\mathbf{P}$ matrix\n",
    "* the update of $\\mathbf{Q}$ matrix\n",
    "\n",
    "You can copy paste all the function in the cell below to make it more practical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_at(i, j, R, P, Qt, beta):\n",
    "    return 0\n",
    "\n",
    "def update_P_at(i, j, R, P, Qt, alpha, beta):\n",
    "    pass\n",
    "        \n",
    "def update_Q_at(i, j, R, P, Qt, alpha, beta):\n",
    "    pass\n",
    "        \n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    # do something\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "['Mahout' 'neural networks' 'support vector machines' 'theory' 'regression'\n",
      " 'libsvm' 'Cassandra']\n",
      "Topic 2\n",
      "['MapReduce' 'Big Data' 'Java' 'Hadoop' 'Storm' 'Spark' 'Cassandra']\n",
      "Topic 3\n",
      "['statistics' 'statsmodels' 'Postgres' 'R' 'C++' 'NoSQL' 'probability']\n",
      "Topic 4\n",
      "['libsvm' 'support vector machines' 'pandas' 'numpy' 'deep learning'\n",
      " 'scipy' 'Big Data']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8b2a898>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABICAYAAAANm7UyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJaTmLiJSQmruIiIlpOYuIlJC/wP51OBm2ZdD5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x876def0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# Print topic keywords\n",
    "\n",
    "plt.imshow(nQ.T, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding L1 penalization\n",
    "Repeat the steps above for the l1 penalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_at(i, j, R, P, Qt, beta):\n",
    "    return 0\n",
    "\n",
    "def update_P_at(i, j, R, P, Qt, alpha, beta):\n",
    "    pass\n",
    "        \n",
    "def update_Q_at(i, j, R, P, Qt, alpha, beta):\n",
    "    pass\n",
    "        \n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002, beta=0.02):\n",
    "    # do something\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1\n",
      "['Mahout' 'neural networks' 'machine learning' 'scikit-learn'\n",
      " 'support vector machines' 'libsvm' 'regression']\n",
      "Topic 2\n",
      "['MapReduce' 'Big Data' 'Hadoop' 'Java' 'Storm' 'Spark' 'Cassandra']\n",
      "Topic 3\n",
      "['statistics' 'statsmodels' 'R' 'Postgres' 'probability' 'MongoDB' 'NoSQL']\n",
      "Topic 4\n",
      "['support vector machines' 'libsvm' 'regression' 'pandas' 'numpy' 'scipy'\n",
      " 'deep learning']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x8bb43c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAABICAYAAAANm7UyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3cyshtzczcxqyM3dzKyG/gc+9np8l0ffeAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x871c978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "# Print topic keywords\n",
    "\n",
    "plt.imshow(nQ.T, vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems\n",
    "The goal of a recommender system is simple: Given a matrix of user/item ratings, infer the rating that would give a user to a given item using the existing ratings.\n",
    "\n",
    "For once, we are being lucky with this problem in NMF, because the  inference comes for free with most algorithms. It boils down to simply putting 0 in the matrix where the data is missing and *not* performing any optimization on these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_at(i, j, R, P, Qt):\n",
    "    return 0\n",
    "\n",
    "def update_P_at(i, j, R, P, Qt, alpha):\n",
    "    pass\n",
    "        \n",
    "def update_Q_at(i, j, R, P, Qt, alpha):\n",
    "    pass\n",
    "        \n",
    "def matrix_factorization(R, P, Q, K, steps=5000, alpha=0.0002):\n",
    "    # do something\n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example belows shows a matrix where the inferred ratings should be obvious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 5 5 1]\n",
      " [4 0 5 1]\n",
      " [1 1 0 5]\n",
      " [1 0 0 4]\n",
      " [0 1 5 4]]\n",
      "[[ 4.88164615  4.95900901  5.17377349  0.83975676]\n",
      " [ 4.14401722  4.20968973  4.83039049  1.1694828 ]\n",
      " [ 0.99458403  1.0103392   5.65908692  4.96755345]\n",
      " [ 1.00258808  1.01847149  4.71307017  3.97474213]\n",
      " [ 1.11478845  1.13244986  4.91387158  4.07933483]]\n"
     ]
    }
   ],
   "source": [
    "R = [\n",
    "     [5,5,5,1],\n",
    "     [4,0,5,1],\n",
    "     [1,1,0,5],\n",
    "     [1,0,0,4],\n",
    "     [0,1,5,4],\n",
    "    ]\n",
    " \n",
    "R = np.array(R)\n",
    " \n",
    "N = len(R)\n",
    "M = len(R[0])\n",
    "K = 2\n",
    " \n",
    "P = np.random.rand(N,K)\n",
    "Q = np.random.rand(M,K)\n",
    "\n",
    "nP, nQ = matrix_factorization(R, P, Q, K)\n",
    "nR = np.dot(nP, nQ.T)\n",
    "\n",
    "print(R)\n",
    "print(nR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing user and item bias\n",
    "When dealing with recommender systems, each user may have its own bias. A movie can also be biased byt the communication around it. In this kind of method, a bias is represented as a constant corresponding to each user and each movie.\n",
    "\n",
    "Modifiy the current system to integrate user and movie bias in your optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical application\n",
    "Now that your matrix factoriazation system is ready, embed it in a sklearn estimator and apply it on the MovieLens 100k using the previous notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
