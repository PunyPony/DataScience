{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing PageRank\n",
    "During this practical session, you will implement PageRank for recommendation.\n",
    "\n",
    "PageRank is decomposed in several steps:\n",
    "- Create a toy dataset\n",
    "- Build the item graph\n",
    "- Implement PageRank\n",
    "- Run PageRank on the dataset to validate its behavior\n",
    "- Implement a recommender based on the PageRank\n",
    "- Adapt the MovieLens validation to use Recall as a validation metric\n",
    "- Compare it to other approches\n",
    "\n",
    "## Building a toy dataset\n",
    "In MovieLens, we know what movies users have seen and how they rated them. For each user, we know when the movie has been seen and what is the rating he gave to it. There are lot of questions here:\n",
    "- directed on undirected? We have the timestamp of movies so we could have directed edges based on time.\n",
    "- threshold or not? Even if a user has disliked a movie, he has seen it so it means it matched his interests. Do we want to show movies the user could find interesting, or movies that he would like?\n",
    "- time window? Should we create links between all the movies a user has seen, or only some of them?\n",
    "\n",
    "But, for now, we are only interested in the technical function of PageRank. Create a small dataset on which you will be able to iterate fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Here we simulate the viewing history of 3 users.\n",
    "# Each line works is as follows:\n",
    "# - a 0 value indicates that the user has not seen the movie\n",
    "# - a nonzero value indicates the viewing order of the movie. 1 means first movie seen, 2 means second, etc.\n",
    "\n",
    "# We want to build the corresponding adjacency matrix.\n",
    "# For example, for the first user, we want to create the edges:\n",
    "# 0 -> 1\n",
    "# 1 -> 3\n",
    "# 3 -> 4\n",
    "\n",
    "# Note that this particular format has been chosen to mimic the adjacency matrix available in the wikipedia example\n",
    "\n",
    "X = [\n",
    "    [1, 2, 0, 3, 4],\n",
    "    [1, 0, 2, 0, 3],\n",
    "    [0, 0, 1, 2, 0],\n",
    "    [2, 0, 0, 0, 1],\n",
    "]\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the adjacency graph\n",
    "We want to build the adjacency graph corresponding to this matrix. It will be of shape ni x ni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ni = len(X[0])\n",
    "\n",
    "def build_adjacency_matrix(ratings):\n",
    "    adjacency_matrix = np.zeros((ni, ni), dtype=int)\n",
    "    i_sorted = np.argsort(ratings)\n",
    "    for rating_line in ratings:\n",
    "        non_zeros_rating_index = np.nonzero(rating_line)[0]\n",
    "        non_zeros_rating_value = rating_line[non_zeros_rating_index]\n",
    "        ordered_index_value = np.argsort(non_zeros_rating_value)\n",
    "        non_zero_argsort_index = non_zeros_rating_index[ordered_index_value]\n",
    "        adjacency_matrix[non_zero_argsort_index[:-1], non_zero_argsort_index[1:]] +=1\n",
    "    return adjacency_matrix\n",
    "\n",
    "adjacency_matrix = build_adjacency_matrix(X)\n",
    "print(adjacency_matrix)\n",
    "\n",
    "# Should produce\n",
    "# [[0 1 1 0 0]\n",
    "#  [0 0 0 1 0]\n",
    "#  [0 0 0 1 1]\n",
    "#  [0 0 0 0 1]\n",
    "#  [1 0 0 0 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement PageRank\n",
    "Reminder: PageRank takes as input an adjacency matrix and outputs a rank for each of the node of the graph. You can implement the stopping criterion as you wish. An interface is proposed but feel free to customize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.25345787]\n",
      " [0.13531093]\n",
      " [0.13531093]\n",
      " [0.20788072]\n",
      " [0.26803955]]\n"
     ]
    }
   ],
   "source": [
    "def page_rank(adjacency_matrix, starting_probas=None, g=0.85, n_iter=100, tol=None):\n",
    "    \"\"\"Compute the (Personalized) PageRank score corresponding to a given adjacency matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    adjacency_matrix: 2D square numpy array of dimension (n, n)\n",
    "      The adjacency matrix of the graph on which to compute PageRank score\n",
    "      \n",
    "    starting_probas: vector of float, optional\n",
    "      Vector of probability to \"teleport\" on each node. By default filled of 1/n, it implements\n",
    "      PageRank. If given the probability for a user to be on other node, it implements personalized\n",
    "      PageRank. This vector must be all non-zero.\n",
    "      \n",
    "    g: float, optional\n",
    "      1 - probability of teleporting to a random node\n",
    "    \n",
    "    n_iter: int, optional\n",
    "      Maximum number of iterations\n",
    "    \n",
    "    tol: float, optional\n",
    "      Tolerance. The algorithm stops as soon as the update magnitude of all values is below this threshold.\n",
    "    \"\"\"\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    if starting_probas is None:\n",
    "        p = np.ones(n)[:, None] / n\n",
    "    else:\n",
    "        p = starting_probas\n",
    "        p = p/p.sum() #to be sure\n",
    "    \n",
    "    last_p = np.full(n, np.inf)\n",
    "    onces = np.ones(shape=(n,n))\n",
    "    step = 0\n",
    "    adjacency_matrix_normalised = adjacency_matrix / np.repeat(adjacency_matrix.sum(axis=1), n).reshape(n,n)\n",
    "    M = (1-g)/n*onces + g*adjacency_matrix_normalised@np.diag(1/adjacency_matrix_normalised.sum(axis=1))\n",
    "\n",
    "    while(np.linalg.norm(p - last_p, 2) > tol and step<100 \n",
    "          if tol is not None\n",
    "          else step<n_iter):\n",
    "        p_last = p\n",
    "        p = M.T@p\n",
    "        step +=1\n",
    "    return p\n",
    "    \n",
    "    \n",
    "my_rank = page_rank(adjacency_matrix, n_iter=13)\n",
    "print(my_rank)\n",
    "\n",
    "# Should produce\n",
    "# [[0.25345787]\n",
    "#  [0.13531093]\n",
    "#  [0.13531093]\n",
    "#  [0.20788072]\n",
    "#  [0.26803955]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate PageRank\n",
    "Now validate you implementation. The best way is to have a reference pageRank matrix with which you can compare yours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(my_rank, np.asarray(\n",
    "    [[0.25345787],\n",
    "     [0.13531093],\n",
    "     [0.13531093],\n",
    "     [0.20788072],\n",
    "     [0.26803955]]))\n",
    "\n",
    "# Should be true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple PageRank recommenders\n",
    "Here are the data available:\n",
    "- An adjacency matrix: This matrix can contain only 1s and 0s\n",
    "- A history for a given user: A user history is a set of movies seen by the user represented as their ids. For example {1, 3} corresponds to a user having seen movies 1 and 3. Therefore, we do not want to recommend him neither 1 or 3. User history is a set of products.\n",
    "\n",
    "We want to do a global recommendation based on PageRank only (no Random Walk).\n",
    "\n",
    "**Note that we must not recommend any item present in user history for any of the following algorithms.**\n",
    "\n",
    "### Step 1: Code a general PageRank recommender\n",
    "If a user has a small history, we want to recommend him the best movie according to a global PageRank.\n",
    "Tips:\n",
    "- In this case, the user history is not used to compute the recommendation. However, we need it to avoid recommending a movie that he has already seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_pr(adjacency_matrix, user_history, n_products):\n",
    "    #products = np.arrange(n_products)\n",
    "    relevants = page_rank(adjacency_matrix).squeeze()\n",
    "    films_id = np.setdiff1d(np.argsort(relevants), user_history)[:n_products]\n",
    "    return films_id\n",
    "\n",
    "recommend_pr(adjacency_matrix, [], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Compute a personalized PageRank\n",
    "Now we will integrate the user history in computation of the PageRank in order to obtain a Personlized PageRank.\n",
    "For example, among 5 movies, a global PageRank will be run using (0.2, 0.2, 0.2, 0.2, 0.2) as starting probas. For a personalized PageRank, if a user has seen the movie 1, we could compute PageRank using (0.1, 0.6, 0.1, 0.1, 0.1). The weighting of the PageRank is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_ppr(adjacency_matrix, user_history, n_products):\n",
    "#     starting_probas = np.ones(len(adjacency_matrix))\n",
    "#     starting_probas[user_history] += 2\n",
    "#     starting_probas = starting_probas / starting_probas.sum()\n",
    "    \n",
    "    relevants = page_rank(adjacency_matrix, starting_probas=None).squeeze()\n",
    "    films_id = np.setdiff1d(np.argsort(relevants), user_history)[:n_products]\n",
    "    return films_id\n",
    "\n",
    "recommend_ppr(adjacency_matrix, [1,2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing a Random Walk\n",
    "In peculiar usages like spotify where a playlist of music is generated on the fly, we do not want to deviate too much from the previous song. One way to implement this is to do a Random Walk in the graph using PageRank as weighting.\n",
    "\n",
    "### Step 1: general recommender with Random Walk\n",
    "The principle is simple. Start points of the random walk are the user history. If user has interacted with items 1 and 3, then the algorithm may start from there. The transition rule is simple:\n",
    "- Let us say your are on node $i$\n",
    "- Successors with their corresponding PR value are:\n",
    "  - $j_1 = 3$\n",
    "  - $j_2 = 5$\n",
    "  - $j_3 = 2$\n",
    "- Then for my Random Walk, my probability to go to:\n",
    "  - $j_1$ is $0.3$\n",
    "  - $j_2$ is $0.5$\n",
    "  - $j_3$ is $0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_pr_rw(adjacency_matrix, user_history, n_products):\n",
    "#     starting_probas = np.ones(len(adjacency_matrix))\n",
    "#     starting_probas[user_history] += 2 \n",
    "#     starting_probas = starting_probas / starting_probas.sum()\n",
    "    \n",
    "    relevants = page_rank(adjacency_matrix, starting_probas=None).squeeze()\n",
    "    films_id = list()\n",
    "    vertex = np.random.choice(user_history, 1) #start\n",
    "    \n",
    "    for i in range(n_products): #On pourrait faire; on ne s'arrete que quand on a n_products recos, lÃ  c'est un maximum.\n",
    "        linked = adjacency_matrix[vertex].nonzero()[1]\n",
    "        vertex = np.random.choice(linked, 1, p=relevants[linked]/relevants[linked].sum())\n",
    "        films_id.append(vertex)\n",
    "    \n",
    "    films_id = np.setdiff1d(np.argsort(relevants), user_history)[:n_products]\n",
    "    return np.array(films_id)\n",
    "\n",
    "recommend_pr_rw(adjacency_matrix, [1,2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: add restart\n",
    "The problem of the previous approach is that we may end up very far from user preferred products. Code a version of the random walk that has a probability to restart (ie go back to a starting node) with probability $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_pr_rw_with_restart(adjacency_matrix, user_history, n_products):\n",
    "    starting_probas = np.ones(len(adjacency_matrix))\n",
    "    starting_probas[user_history] += 0\n",
    "    starting_probas = starting_probas / starting_probas.sum()\n",
    "    \n",
    "    relevants = page_rank(adjacency_matrix, starting_probas=starting_probas).squeeze()\n",
    "    films_id = list()\n",
    "    vertex = np.random.choice(user_history, 1) #start\n",
    "    \n",
    "    for i in range(n_products): #On pourrait faire; on ne s'arrete que quand on a n_products recos, lÃ  c'est un maximum.\n",
    "        linked = adjacency_matrix[vertex].nonzero()[1]\n",
    "        vertex = np.random.choice(np.union1d(user_history, linked), 1, p=[0.1/len(user_history) \n",
    "                                                                          if v in user_history \n",
    "                                                                          else relevants[linked]/relevants[linked].sum()*0.9\n",
    "                                                                          for v in np.union1d(user_history, linked)])\n",
    "        films_id.append(vertex)\n",
    "    \n",
    "    films_id = np.setdiff1d(np.argsort(relevants), user_history)[:n_products]\n",
    "    return np.array(films_id)\n",
    "\n",
    "recommend_pr_rw_with_restart(adjacency_matrix, [1,2], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] Code the recall metric\n",
    "Reminder:\n",
    "    $$\\frac{number\\_of\\_relevant\\_items\\_predicted}{number\\_of\\_relevant\\_items\\_for\\_the\\_user}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(Y_predicted, Y_true):\n",
    "    return np.sum(Y_predicted == Y_true)/ Y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional] MovieLens evaluation\n",
    "For the first session, we coded an evaluation framework based on MovieLens. The goal was to infer movie ratings. The setting of the problem has now changed: the goal is to predict 10 products that a user is likely to watch.\n",
    "Adapt the system to be able to evaluate recall on this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
